{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class LRBoostRegressor(RegressorMixin, BaseEstimator):\n",
    "    def __init__(self, primary_model=None, secondary_model=None):\n",
    "        if primary_model is None:\n",
    "            primary_model = RidgeCV()\n",
    "\n",
    "        if secondary_model is None:\n",
    "            secondary_model = HistGradientBoostingRegressor()\n",
    "\n",
    "        self.primary_model = primary_model\n",
    "        self.secondary_model = secondary_model\n",
    "        self.secondary_type = type(self.secondary_model).__name__\n",
    "\n",
    "    def __sklearn_is_fitted__(self):\n",
    "        \"\"\"Internal sklearn helper that indicates the object has been fitted\n",
    "\n",
    "        Returns:\n",
    "            bool: True\n",
    "        \"\"\"\n",
    "        return True\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        \"\"\"Fits both the primary and secondary estimator and returns fitted LRBoostRegressor\n",
    "\n",
    "        Args:\n",
    "            X (array-like): Input features\n",
    "            y (array-like): Raw target\n",
    "            sample_weight (array-like, optional): Sample weights for estimators.\n",
    "                Only accepts one weight for both. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            self: Fitted LRBoostRegressor\n",
    "        \"\"\"\n",
    "        self._fit_primary_model(X, y, sample_weight=sample_weight)\n",
    "        self.primary_residual = np.subtract(self.primary_prediction, y)\n",
    "        self._fit_secondary_model(X, self.primary_residual, sample_weight=sample_weight)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _fit_primary_model(self, X, y, sample_weight=None):\n",
    "        self.primary_model.fit(X, y, sample_weight=sample_weight)\n",
    "        self.primary_prediction = self.primary_model.predict(X)\n",
    "\n",
    "    def _fit_secondary_model(self, X, y, sample_weight=None):\n",
    "        self.secondary_model.fit(X, y, sample_weight=sample_weight)\n",
    "\n",
    "    def predict(self, X, detail=False):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            X (array-type): Input features\n",
    "            detail (bool, optional):  Flag to include primary and secondary predictions.\n",
    "                Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            Dict: If detail=True with primary, secondary, and final predictions.\n",
    "            np.array: If detail=False just final predictions.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "        primary_prediction = self.primary_model.predict(X)\n",
    "\n",
    "        if self.secondary_type == \"NGBRegressor\":\n",
    "            secondary_prediction = self.secondary_model.pred_dist(X).loc\n",
    "        elif self.secondary_type == \"XGBDistribution\":\n",
    "            secondary_prediction = self.secondary_model.predict(X).loc\n",
    "        else:\n",
    "            secondary_prediction = self.secondary_model.predict(X)\n",
    "\n",
    "        if detail:\n",
    "\n",
    "            preds = {\n",
    "                \"primary_prediction\": primary_prediction,\n",
    "                \"secondary_prediction\": secondary_prediction,\n",
    "                \"final_prediction\": np.subtract(\n",
    "                    primary_prediction, secondary_prediction\n",
    "                ),\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            preds = np.subtract(primary_prediction, secondary_prediction)\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def predict_dist(self, X) -> tuple:\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            X (array-like): Input features\n",
    "\n",
    "        Raises:\n",
    "            Exception: Throws error if non probabilistic model used.\n",
    "\n",
    "        Returns:\n",
    "            tuple: final prediction, sd of secondary prediction\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        if not self.secondary_type in [\"NGBRegressor\", \"XGBDistribution\"]:\n",
    "            raise Exception(\n",
    "                \"predict_dist() method requires an NGboostRegressor or XGBDistribution object\"\n",
    "            )\n",
    "\n",
    "        if self.secondary_type == \"NGBRegressor\":\n",
    "            preds = self.secondary_model.pred_dist(X)\n",
    "            final_prediction = np.add(preds.loc, self.primary_model.predict(X))\n",
    "            return final_prediction, preds.scale\n",
    "\n",
    "        if self.secondary_type == \"XGBDistribution\":\n",
    "            preds = self.secondary_model.predict(X)\n",
    "            final_prediction = np.add(preds.loc, self.primary_model.predict(X))\n",
    "            return final_prediction, preds.scale\n",
    "\n",
    "    def fit_and_tune(\n",
    "        self,\n",
    "        X,\n",
    "        y,\n",
    "        tuner,\n",
    "        param_distributions,\n",
    "        sample_weight=None,\n",
    "        primary_fit_params=None,\n",
    "        secondary_fit_params=None,\n",
    "        *tuner_args,\n",
    "        **tuner_kwargs\n",
    "    ):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            X ([type]): [description]\n",
    "            y ([type]): [description]\n",
    "            tuner ([type]): [description]\n",
    "            param_distributions ([type]): [description]\n",
    "            sample_weight ([type], optional): [description]. Defaults to None.\n",
    "            primary_fit_params ([type], optional): [description]. Defaults to None.\n",
    "            secondary_fit_params ([type], optional): [description]. Defaults to None.\n",
    "\n",
    "        Raises:\n",
    "            Exception: [description]\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        if primary_fit_params is None:\n",
    "            primary_fit_params = {}\n",
    "\n",
    "        if (\n",
    "            \"sample_weight\" in primary_fit_params\n",
    "            or \"sample_weight\" in secondary_fit_params\n",
    "        ) and sample_weight is not None:\n",
    "            raise Exception(\"Conflicting sample weights.\")\n",
    "\n",
    "        self._fit_primary_model(X, y, sample_weight=sample_weight, **primary_fit_params)\n",
    "        self._tune_secondary_model(\n",
    "            tuner,\n",
    "            param_distributions,\n",
    "            X,\n",
    "            y,\n",
    "            *tuner_args,\n",
    "            sample_weight=sample_weight,\n",
    "            fit_params=secondary_fit_params,\n",
    "            **tuner_kwargs\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def _tune_secondary_model(\n",
    "        self,\n",
    "        tuner,\n",
    "        param_distributions,\n",
    "        X,\n",
    "        y,\n",
    "        *tuner_args,\n",
    "        sample_weight=None,\n",
    "        secondary_fit_params=None,\n",
    "        **tuner_kwargs\n",
    "    ):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            tuner ([type]): [description]\n",
    "            param_distributions ([type]): [description]\n",
    "            X ([type]): [description]\n",
    "            y ([type]): [description]\n",
    "            sample_weight ([type], optional): [description]. Defaults to None.\n",
    "            secondary_fit_params ([type], optional): [description]. Defaults to None.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self.primary_model)\n",
    "        if secondary_fit_params is None:\n",
    "            secondary_fit_params = {}\n",
    "\n",
    "        self.secondary_model = (\n",
    "            tuner(\n",
    "                self.secondary_model, param_distributions, *tuner_args, **tuner_kwargs\n",
    "            )\n",
    "            .fit(X, y, sample_weight=sample_weight, **secondary_fit_params)\n",
    "            .best_estimator_\n",
    "        )\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clutch = pd.read_csv(\"../examples/clutch_vs_nonclutch_minutes.csv\")\n",
    "\n",
    "high_min_players = clutch.loc[clutch.loc['clutch']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrb = LRBoostRegressor()\n",
    "lrb.fit(X_train, y_train.ravel())\n",
    "detailed_predictions = lrb.predict(X_test, detail=True)\n",
    "primary_predictions = detailed_predictions['primary_prediction']\n",
    "lrb_predictions = detailed_predictions['final_prediction']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb = HistGradientBoostingRegressor()\n",
    "hgb.fit(X_train, y_train.ravel())\n",
    "hgb_predictions = hgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary RMSE: 11.73\n",
      "LRBoost RMSE: 13.28\n",
      "HistGradientBoostingRegressor RMSE: 11.47\n"
     ]
    }
   ],
   "source": [
    "print(f\"Primary RMSE: {round(mean_squared_error(primary_predictions, y_test.ravel()), 2)}\")\n",
    "print(f\"LRBoost RMSE: {round(mean_squared_error(lrb_predictions, y_test.ravel()), 2)}\")\n",
    "print(f\"HistGradientBoostingRegressor RMSE: {round(mean_squared_error(hgb_predictions, y_test.ravel()), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "concrete = pd.read_csv(\"../examples/concrete_data.csv\")\n",
    "features = ['cement', 'slag', 'fly_ash', 'water', 'superplastic', 'coarse_agg', 'fine_agg', 'age', 'cw_ratio']\n",
    "target = 'ccs'\n",
    "\n",
    "def evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    lrb = LRBoostRegressor(primary_model=RidgeCV(alphas=np.logspace(-4, 3, 10, endpoint=True)))\n",
    "    lrb.fit(X_train, y_train.ravel())\n",
    "    detailed_predictions = lrb.predict(X_test, detail=True)\n",
    "    primary_predictions = detailed_predictions['primary_prediction']\n",
    "    lrb_predictions = detailed_predictions['final_prediction']\n",
    "    hgb = HistGradientBoostingRegressor()\n",
    "    hgb.fit(X_train, y_train.ravel())\n",
    "    hgb_predictions = hgb.predict(X_test)\n",
    "    print(f\"Ridge RMSE: {round(mean_squared_error(primary_predictions, y_test.ravel()), 2)}\")\n",
    "    print(f\"HistGradientBoostingRegressor RMSE: {round(mean_squared_error(hgb_predictions, y_test.ravel()), 2)}\")\n",
    "    print(f\"LRBoost RMSE: {round(mean_squared_error(lrb_predictions, y_test.ravel()), 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE: 112.4\n",
      "HistGradientBoostingRegressor RMSE: 26.33\n",
      "LRBoost RMSE: 25.06\n"
     ]
    }
   ],
   "source": [
    "## Scenario 1: 75/25 train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(concrete[features], concrete[target], train_size=0.75, random_state=100)\n",
    "evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE: 107.6\n",
      "HistGradientBoostingRegressor RMSE: 26.6\n",
      "LRBoost RMSE: 23.55\n"
     ]
    }
   ],
   "source": [
    "## Scenario 1: 50/50 train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(concrete[features], concrete[target], train_size=0.50, random_state=100)\n",
    "evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE: 89.26\n",
      "HistGradientBoostingRegressor RMSE: 4.21\n",
      "LRBoost RMSE: 3.7\n"
     ]
    }
   ],
   "source": [
    "## Scenario 3: Training: CCS > 25, Testing: CCS <= 25\n",
    "train = concrete.loc[concrete['ccs'] > 25]\n",
    "test = concrete.loc[concrete['ccs'] <= 25]\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_test = train[features]\n",
    "y_test = train[target]\n",
    "evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5125629767961006\n",
      "0.9332998430230678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from lrboost import LRBoostRegressor\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "lrb = LRBoostRegressor().fit(X, y)\n",
    "predictions = lrb.predict(X)\n",
    "detailed_predictions = lrb.predict(X, detail=True)\n",
    "print(lrb.primary_model.score(X, y))\n",
    "print(lrb.score(X, y))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "851ec02c8773162f7c1b97803a5edfe2e0978958fabe5e41139935c3247d6e90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('lrboost': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
