{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "from sklearn.utils.validation import (\n",
    "    check_is_fitted,\n",
    "    check_consistent_length,\n",
    "    _check_sample_weight,\n",
    ")\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRBoostRegressor():\n",
    "    \n",
    "    def __init__(self, linear_model=RidgeCV(), non_linear_model=HistGradientBoostingRegressor()):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            linear_model (optional): Linear model (not enforced) for initial fit. MUST BE SKLEARN COMPLIANT. Defaults to RidgeCV().\n",
    "            non_linear_model (optional): Non-Linear model (not enforced) for initial fit. MUST BE SKLEARN COMPLIANT. Defaults to HistGradientBoostingRegressor().\n",
    "        \"\"\"\n",
    "        self.linear_model = linear_model\n",
    "        self.non_linear_model = non_linear_model\n",
    "\n",
    "    def __sklearn_is_fitted__(self):\n",
    "        return True\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        self.linear_model.fit(X, y, sample_weight=sample_weight)\n",
    "        linear_prediction = self.linear_model.predict(X)\n",
    "        linear_residual = np.subtract(linear_prediction, y)\n",
    "        self.non_linear_model.fit(X, y=linear_residual, sample_weight=sample_weight)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X) -> np.array:\n",
    "        check_is_fitted(self)\n",
    "        non_linear_prediction = self.non_linear_model.predict(X)\n",
    "        linear_prediction = self.linear_model.predict(X)\n",
    "\n",
    "        return np.add(non_linear_prediction, linear_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125064631553949"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "lrb = LRBoostRegressor().fit(X, y)\n",
    "predictions = lrb.predict(X)\n",
    "mean_squared_error(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15024071867057287"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "## Example of how to pass arguments to constituent estimators\n",
    "ridge_args = {\"alphas\": np.logspace(-4, 3, 10, endpoint=True),\n",
    "               \"cv\": 5}\n",
    "\n",
    "rf_args = {\"n_estimators\": 50, \n",
    "            \"n_jobs\": -1}\n",
    "\n",
    "lrb = LRBoostRegressor(linear_model=RidgeCV(**ridge_args),\n",
    "                        non_linear_model=RandomForestRegressor(**rf_args))\n",
    "lrb = lrb.fit(X, y)\n",
    "predictions = lrb.predict(X)\n",
    "mean_squared_error(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "def ridge(X, y):\n",
    "    args = {\"alphas\": (1000, 100000), \"cv\": (5)}\n",
    "    mod = RidgeCV(**args).fit(X, y)\n",
    "    preds = mod.predict(X)\n",
    "    return(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categorical_features': None,\n",
       " 'early_stopping': 'auto',\n",
       " 'l2_regularization': 0.0,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'squared_error',\n",
       " 'max_bins': 255,\n",
       " 'max_depth': None,\n",
       " 'max_iter': 50,\n",
       " 'max_leaf_nodes': 31,\n",
       " 'min_samples_leaf': 10,\n",
       " 'monotonic_cst': None,\n",
       " 'n_iter_no_change': 10,\n",
       " 'random_state': None,\n",
       " 'scoring': 'loss',\n",
       " 'tol': 1e-07,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrb.non_linear_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LRBoostRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rj/scn4tpq1041dnlh379lxrljr0000gn/T/ipykernel_32105/2020692386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \"n_jobs\": -1}\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m lrb = LRBoostRegressor(linear_model=RidgeCV(**ridge_args),\n\u001b[0m\u001b[1;32m     13\u001b[0m                         non_linear_model=RandomForestRegressor(**rf_args))\n\u001b[1;32m     14\u001b[0m \u001b[0mlrb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlrb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LRBoostRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "## Example of how to pass arguments to constituent estimators\n",
    "ridge_args = {\"alphas\": np.logspace(-4, 3, 10, endpoint=True),\n",
    "               \"cv\": 5}\n",
    "\n",
    "rf_args = {\"n_estimators\": 50, \n",
    "            \"n_jobs\": -1}\n",
    "\n",
    "lrb = LRBoostRegressor(linear_model=RidgeCV(**ridge_args),\n",
    "                        non_linear_model=RandomForestRegressor(**rf_args))\n",
    "lrb = lrb.fit(X, y)\n",
    "predictions = lrb.predict(X)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "851ec02c8773162f7c1b97803a5edfe2e0978958fabe5e41139935c3247d6e90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('lrboost': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
